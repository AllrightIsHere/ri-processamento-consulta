{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Este projeto você irá implementar o processamento de consultas. Nela, você utilizará o índice para retornar uma coleção ordenada e avaliação de algumas consultas selecionadas. Para isso, vocês deverão implementar alguns métodos das seguintes classes.\n",
    "\n",
    "- `IndexPreComputedVals`: Em alguns modelos, há a necessidade de processar alguns valores para que, no momento da execução da consulta, seja retornado de forma mais rápida. Esta classe analisa o índice e armazena informações necessárias para o calculo de cada tipo de modelagem;\n",
    "- `RankingModel`: Classe abstrata para a criação dos modelos. Ele possui o método `get_ordered_docs` a ser implementado por suas subclasses;\n",
    "- `BooleanRankingModel` Classe que retorna um resultado de consulta por meio do [modelo booleano](https://docs.google.com/presentation/d/1V62ll_IXRrsp6TYUHjx_T4jIyIc1ZVJYoOSwsxObybE/edit?usp=sharing)\n",
    "- `VectorRankingModel`: Classe que retorna um resultado de consulta por meio do [modelo vetorial](https://docs.google.com/presentation/d/1jsD1MpLIl08OnWysDhjp7glc4_K0sH9sKUhRqI8lLLo/edit?usp=sharing)\n",
    "- `QueryRunner`: Classe principal encarregada de obter a consulta e retornar os resultados;\n",
    "\n",
    "\n",
    "Este trabalho depende do código do indice (pacote `index`). Assim, você deve adicioná-o apropriadamente para dar continuidade ao projeto. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelagem Booleana e Vetorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 1 - Modelagem Booleana**: A abordagem booleana neste trabalho é simplificada. O modelo possui o atributo `operator` que é uma instancia do [Enum](https://docs.python.org/3.4/library/enum.html) Operator. Caso o operador seja AND, será feito a operacao de interseção entre todos os documentos contidos ocorrencias de palavras, caso contrario, sendo OR, será feito a união. Exemplo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from index.structure import TermOccurrence\n",
    "map_ocorrencias = {\"saturno\":[TermOccurrence(1,1,1),\n",
    "                            TermOccurrence(3,1,1)],\n",
    "                     \"plutao\":[TermOccurrence(2,5,1),\n",
    "                               TermOccurrence(4,5,1)],\n",
    "                        \"terra\":[TermOccurrence(1,2,1),\n",
    "                            TermOccurrence(2,2,1),\n",
    "                            TermOccurrence(4,2,1),],\n",
    "                        \"venus\":[TermOccurrence(1,3,1),\n",
    "                                TermOccurrence(2,3,1),\n",
    "                                TermOccurrence(3,3,1),\n",
    "                                TermOccurrence(4,3,1)],\n",
    "                        \"marte\":[TermOccurrence(1,4,2),\n",
    "                            TermOccurrence(3,4,1),\n",
    "                            TermOccurrence(4,4,1),],\n",
    "\n",
    "                        \"mercurio\":[TermOccurrence(3,6,1)]          \n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1, 2, 3, 4}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{1,2,3}|{2,4}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A intereseção entre `saturno` e `venus` resultará nos documentos 1 e 3 e, a união, nos documentos 1, 2, 3 e 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta é uma forma bem simplificada para implementarmos o modelo booleano. Para isso, você deverá implementar os métodos `union_all` e `intersection_all` presentes na classe `BooleanRankingModel` no arquivo `ranking_models.py`. Esses métodos recebem como parâmetro um mapa com a lista de correncias de cada termo (similar a exemplificada acima)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.000s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m query.tests.ranking_models RankingModelTest.test_boolean_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 2 - TF-IDF:** Agora, no mesmo arquivo, iremos finalizar a implementação do modelo Vetorial utilizando a classe `VectorRankingModel`. Nesta classe, primeiramente, você deverá implementar os [métodos estáticos](https://daniel-hasan.github.io/cefet-web-grad/classes/python2/) `tf`, `idf` e `tf_idf`. Sendo que $TF = 1+log_2(f_{ij})$ e $IDF_i = log_2(\\frac{N}{n_i})$ em que $f_{ij}$ é a frequência do termo $i$ no documento $j$, $N$ é o número de documentos e $n_i$ é o número de documentos que ocorrem o termo $i$. Abaixo, faça testes destes métodos: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{3.7369655941662066, 6.321928094887363, 23.624827779386788}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from query.ranking_models import VectorRankingModel\n",
    "\n",
    "doc_count = 200\n",
    "freq_term = 40\n",
    "num_docs_with_term = 15\n",
    "# Esperado> {3.7369655941662066, 6.321928094887363, 23.624827779386788}\n",
    "\n",
    "tf = VectorRankingModel.tf(freq_term)\n",
    "idf = VectorRankingModel.idf(doc_count, num_docs_with_term)\n",
    "tf_idf = VectorRankingModel.tf_idf(doc_count, freq_term, num_docs_with_term)\n",
    "\n",
    "{tf, idf, tf_idf}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 3 - PreComputedVals:** No modelo vetorial temos que calcular a norma de cada documento $d_j$. Esse cálculo pode ser feito durante o preprocessamento da consulta. Assim, na classe `IndexPreComputedVals` possui o atributo `document_norm` que é um dicionário que mapeia cada documento $j$ à sua norma. Esse calculo é feito apenas uma vez ao iniciar o programa. \n",
    "\n",
    "Desta forma, você deverá terminar de implementar o método `precompute_vals` que percorre todo o índice e armazena a norma de cada documento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.011s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m query.tests.ranking_models RankingModelTest.test_precomputed_vals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 4 - Método `get_ordered_docs` da classe `VectorRankingModel`:** Usando os métodos implementados anteriormente você deverá ordenar os documentos contidos no mapa de ocorrencias `docs_occur_per_term` de acordo com a consulta `query` utilizando o modelo vetorial. O parametro `query` mapeia um termo presente na consulta, para a sua ocorrencia (objeto da classe `TermOcurrence`) na propria consulta. \n",
    "\n",
    "Para cada termo $t$ que ocorre na consulta, `docs_occur_per_term` mapeia cada termo com a lista de ocorrencias dele no índice. Veja abaixo um exemplo destes parametros usando a consulta `to be or not to be`.  Veja que, na consulta, `doc_id = None`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = {\"to\":TermOccurrence(None, 1, 2),\n",
    "         \"be\":TermOccurrence(None, 2, 2),\n",
    "          \"or\":TermOccurrence(None, 3, 1),\n",
    "          \"not\":TermOccurrence(None, 4, 1),}\n",
    "docs_occur_per_term = {\n",
    "                                    \"to\":[TermOccurrence(1, 1, 4),\n",
    "                                          TermOccurrence(2, 1, 1),],\n",
    "                                      \"be\":[TermOccurrence(1, 2, 1),TermOccurrence(2, 2, 1)],\n",
    "                                     \"or\":[TermOccurrence(2, 3, 1)],\n",
    "                                    \"not\":[TermOccurrence(3, 4, 1)],\n",
    "                                }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nesse exemplo, temos a consulta (representado pela variavel `query`) 'to to be be or not', ou seja, o `to` e o `be` ocorrendo duas vezes na consulta e, os demais termos, uma vez - a ordem não é definida no parametro. Em `docs_occcur_per_term` temos a ocorrencia desses termos nos documentos da coleção. \n",
    "\n",
    "Você deve executar o modelo vetorial para obter o resultado `documents_weight` que mapeia, para cada documento a similaridade entre ele e a consulta utilizando o modelo vetorial e a distancia do cosseno. Note que neste método você **não** pode navegar por todos os documentos da coleção pois, caso seja feito isso, o código de vocês iriam demorar muito caso sua coleção tiver milhões ou bilhões de documentos. Uma dica é usar o `documents_weight` para armazenar os valores intermediarios do somatorio de $w_{ij} \\times  w_{iq}$, tais variáveis são definidas nos [slides de modelagem vetorial](https://docs.google.com/presentation/d/1jsD1MpLIl08OnWysDhjp7glc4_K0sH9sKUhRqI8lLLo/edit?usp=sharing). \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esse método retorna dois valores: (a) uma lista de ids de documentos ordenada de acordo com o modelo vetorial - use o método e um dicionário que mapeia, para cada documento, o seu peso. O método `rank_document_ids` será útil. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.009s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m query.tests.ranking_models RankingModelTest.test_vector_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Processamento da Consulta e Avaliação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora você irá fazer o processamento da consulta, informada pelo usuário, além de sua avaliação. A implementação do processamento de consultas será feito na classe `QueryRunner` do arquivo `processing.py`.\n",
    "\n",
    "**Requisito antes de começar:** o código que foi feito da indexação deve estar funcionando. Será utilizado a base de dados da Wikipédia. Você não deverá fazer a indexação toda quando iniciar o programa, ao invés disso, você deve persistir o indice todo em arquivo após a indexação. Usando FileIndex, como as ocorrencias já estão armazenadas em arquivo, você precisa armazenar apenas o conteúdo do `dic_index`. A [biblioteca json](https://docs.python.org/3/library/json.html) pode ajudar. Este índice será lido do arquivo apenas uma vez no início da execução do programa."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Criação da coleção de referência:** Para o projeto realizaremos uma avaliação bem simples, com o único intuito de simularmos um processo real de avaliação. Para tanto, consideraremos como conjunto de consultas de teste apenas três consultas:\n",
    "'Irlanda'\n",
    "'Belo Horizonte' e \n",
    "'São Paulo'\n",
    "\n",
    "O conjunto de documentos de teste compreenderá todas as páginas da base de dados da Wikipédia PT-BR utilizadas no projeto.  Para cada consulta, disponibilizamos um arquivo (na pasta `relevant_docs`) com o id de documentos relevantes (separados por vírgula) para as consultas teste.\n",
    "\n",
    "Por exemplo, um documento $D$ será considerado relevante para a consulta 'Belo Horizonte' somente \n",
    "se o id de $D$ estiver no arquivo `belo_horizonte.dat`. Você irá armazenar o conteúdo desses arquivos em memória para diminuir o tempo de busca. Feito isso, a coleção de referência para as três consultas estará montada e pode-se realizar os cálculos de avaliação corretamente.\n",
    "\n",
    "**Como um artigo foi considerado relevante para uma determinada consulta?** A Wikipedia organiza seus artigos em diversas categorias. Assim, para considerarmos se um artigo da Wikipédia é relevante, utilizamos essas categorias. Assim, para os documentos relevantes para a consulta 'Irlanda' (Arquivo `irlanda.dat`), foram considerados relevantes artigos da seguintes categorias: \n",
    " \n",
    "- Irlanda\n",
    "- Economia da Irlanda\n",
    "- História da Irlanda\n",
    "- Cultura da Irlanda\n",
    "- Romancistas da Irlanda\n",
    "- Físicos da Irlanda\n",
    "- Reis da Irlanda\n",
    "- Lordes da Irlanda\n",
    "\n",
    "Categorias relevantes para a consulta 'Belo Horizonte' (Arquivo `belo_horizonte.dat`): \n",
    "\n",
    "- Bairros de Belo Horizonte\n",
    "- Bandas de Belo Horizonte\n",
    "- Belo Horizonte\n",
    "- Edifícios de Belo Horizonte\n",
    "- Metrô de Belo Horizonte\n",
    "- Naturais de Belo Horizonte\n",
    "- Prefeitos de Belo Horizonte\n",
    "- Vereadores de Belo Horizonte\n",
    "\n",
    "Categorias relevantes para a consulta 'São Paulo' (arquivo `sao_paulo.dat`):\n",
    "\n",
    "- Atrações turísticas da cidade de São Paulo\n",
    "- Áreas protegidas de São Paulo\n",
    "- Prefeitos de São Paulo\n",
    "- São Paulo\n",
    "- Turismo em São Paulo\n",
    "- Universidades de São Paulo\n",
    "- Rodovias de São Paulo\n",
    "- Museus da cidade de São Paulo\n",
    "- Governadores de São Paulo\n",
    "- Municípios de São Paulo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 5 - Leitura dos arquivos de relevâncias:** Você deverá implementar o método `get_relevance_per_query` que irá ler todos os arquivo da pasta `relevant_docs` e, com isso, retornar um mapeamento em que a chave é a string de consulta e o valor é o **conjunto** de ids de documentos. Veja um exemplo de retorno com as consultas `Bolívia`, `Brasil` e `Porto Seguro`: \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "retorno = {\"Bolívia\":{1,3,5,6,233},\n",
    "            \"Brasil\":{2,4,5,3},\n",
    "           \"Porto Seguro\":{3,43,21,3,12,233}\n",
    "          }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Faça um teste de execução abaixo: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.019s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_get_relevance_per_query\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 6 - count_top_n_relevant:** Um método que auxilirará vocês na avaliação é o método count_top_n_relevant da classe Query Runner.  Esse método calcula a quantidade de documentos relevantes nas top `n` posições da lista `lstResposta` que é a resposta a uma consulta - lista de ids de documentos. `lstResposta` será a lista de respostas ordenadas por um método de processamento de consulta (BM25, Modelo vetorial). Os ids de documentos relevantes estão no parametro `docRelevantes`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.014s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_count_top_n_relevant"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 7 - processamento da consulta**: O método `get_query_term_occurence` a consulta da mesma forma que foi preprocessado o texto do documento (use a classe `Cleaner` para isso). Este método irá retonar a consulta em um dicionario em que chave é o termo que ocorreu e o valor é uma instancia da classe TermOccurrence (ver Atividade 4). O doc_id deverá ser sempre None. Caso o termo nao exista no indice, ele será desconsiderado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta: crocodilo\n",
      "Resposta do método: {}\n",
      "Resposta esperada: {}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\disan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 5.030s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Consulta: vocês\n",
      "Resposta do método: {'vocês': ( doc: None term_id:1 freq: 1)}\n",
      "Resposta esperada: {'vocês': ( doc: None term_id:1 freq: 1)}\n",
      "\n",
      "Consulta: Vocês estejam\n",
      "Resposta do método: {'vocês': ( doc: None term_id:1 freq: 1), 'estejam': ( doc: None term_id:4 freq: 1)}\n",
      "Resposta esperada: {'vocês': ( doc: None term_id:1 freq: 1), 'estejam': ( doc: None term_id:4 freq: 1)}\n",
      "\n",
      "Consulta: vocês vocês crocodilo\n",
      "Resposta do método: {'vocês': ( doc: None term_id:1 freq: 2)}\n",
      "Resposta esperada: {'vocês': ( doc: None term_id:1 freq: 2)}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_get_query_term_occurence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 8 - Recuperação dos termos da consulta no índice:** O método `get_occurrence_list_per_term` possui com parametro a lista de termos da consulta. Este método retorna um dicionario com a lista de ocorrencia no indice de cada termo passado como parametro. Caso o termo não exista, este termo possuirá uma lista vazia. Veja o exemplo na atividade 4."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Termos: ['crocodilo']\n",
      "Resposta do método: {'crocodilo': []}\n",
      "\n",
      "Termos: ['vocês', 'estejam', 'crocodilo']\n",
      "Resposta do método: {'vocês': [( doc: 2 term_id:1 freq: 3), ( doc: 3 term_id:1 freq: 1)], 'estejam': [( doc: 3 term_id:4 freq: 1)], 'crocodilo': []}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.026s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_get_occurence_list_per_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 9 - processamento da consulta:** Este método recebe como parametro a consulta, os valores precomputado do índice e o dicionário de documentos relevantes (extraídos do método `get_relevance_per_query`) para retornar uma lista de IDs ordenados de acordo com a consulta utilizando o modelo de ranking e indice que são os atributos `index` e "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pesos dos documento da consulta 'crocodilo': {}\n",
      "\n",
      "Pesos dos documento da consulta 'vocês': {2: 0.40378886090583005, 3: 0.12190858668225728}\n",
      "\n",
      "Pesos dos documento da consulta 'Vocês estejam': {2: 0.40378886090583005, 3: 1.0168945556805116}\n",
      "\n",
      "Pesos dos documento da consulta 'vocês vocês crocodilo': {2: 0.8075777218116601, 3: 0.24381717336451456}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      ".\n",
      "----------------------------------------------------------------------\n",
      "Ran 1 test in 0.025s\n",
      "\n",
      "OK\n"
     ]
    }
   ],
   "source": [
    "!python3 -m query.tests.processing ProcessingTest.test_get_docs_term"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Atividade 10: Método estático runQuery e criação da interface de caracteres - ou uso da interface gráfica/web:** Você deverá o método `runQuery` que utilizando o indice, valores precomputados e o dicionario de indices relevantes irá fazer:\n",
    "\n",
    "- Instanciar um objeto de uma subclasse de RankingModel, de acordo com o que foi solicitado pelo usuário\n",
    "- Preprocessar os termos da consulta\n",
    "- Obter no indice as ocorrencias de cada termo do indice\n",
    "- Utilize o método get_docs_term para obter a lista de documentos que responde esta consulta\n",
    "- Caso seja uma consulta que possua documentos relevantes assinalados, fazer a avaliação da precisão e revocação dos top 10, 20 e 50\n",
    "- Imprimir as top 10 respostas. \n",
    "\n",
    "Caso  opte por fazer uma interface de web, você não precisará de fazer este método em especifico  - nem o `main`, explicado a seguir - , mas, deverá possibilitar o usuário entre com uma consulta e retorne as top 10 respostas além de imprimir a precisão e revocação dos top 10, 20 e 50 das consultas que possuem documentos relevantes assinalados. \n",
    "            \n",
    "Caso opte por implementar uma interface de carcteres você deverá terminar de implementar o método `main` para solicitar ao usuário a consulta e execute-a abaixo. Caso deseje, ao inves disso, você pode também fazer uma interface gráfica. Para testar este método, você deverá usar o indice da Wikipedia, assim, ele deve ser lido no início do programa. Você tem a liberdade de alterar este método como bem entender, mas lembre-se que os valores precomputados devem ser executado uma vez só durante a execução do programa antes da solicitação das consultas para que a consulta não fique lenta. Além disso, você deve ler o arquivo do índice também apenas uma vez (não indexe a Wikipedia novamente e sim leia o arquivo do indice gravado em memória). Caso deseje, você pode modificar o IndexPreComputedVals para armazenar mais elementos precomputados que facilitariam a consulta (ou a exibição da mesma). \n",
    "\n",
    "\n",
    "Para melhorar a apresentação, o arquivo `titlePerDoc.dat` apresenta o título do artigo por id do mesmo. Além disso, você deverá fazer uma análise e acordo com o [guia de escrita do relatório](https://docs.google.com/document/d/1spwD-rzJi3xHV8p5cIAmjSHyVEzytChuBTnEDwBaDNQ/edit#heading=h.bsvivts5y2ld) considerando as [tarefas do Trabalho Prático 3](https://docs.google.com/document/d/1spwD-rzJi3xHV8p5cIAmjSHyVEzytChuBTnEDwBaDNQ/edit#heading=h.fh1qug6oeoe7).\n",
    "\n",
    "\n",
    "Caso opte por fazer uma interface web, deve estar claro, neste Jupyter, as instruções para que seja possível executa-la, inclusive, as suas dependencias. Para melhoria de organização, a parte de interface grafica ou web deve ser feita em outros arquivos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "vscode": {
   "interpreter": {
    "hash": "43694f8278121c774a392ac4e3d3685bb4eaaf74f249810dcc8c330b59cc5f6d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
